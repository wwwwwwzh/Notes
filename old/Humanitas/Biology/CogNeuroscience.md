- what is embodied cognitoin/computationlsim/amodal cognition/connectionsm/Ecological Psychology
- what is multimodal, why can't multimodal activate modality specific areas
-  what are symbols and representations, are latents representatiioins and considered in comp
-x what does it mean that mind is not a computer
- impoverished stiimuli and need of infeerence; The motions of an organism create an ever-changing pattern of stimulation in which invariant features surface. The detection of these invariants, according to the ecological psychologist, provides all the information necessary for perception. Insights like these have encouraged embodied cognition proponents to seek explanations of cognition that minimize or disavow entirely the role of inference and, hence, the need for computation. wtf?
-  The body (and, perhaps, parts of the world) does more than merely contribute causally to cognitive processes: it plays a constitutive role in cognition, literally as a part of a cognitive system. 
- J. L. Mackie argues that usual talk of "cause" in fact refers to INUS conditions (insufficient but non-redundant parts of a condition which is itself unnecessary but sufficient for the occurrence of the effect).

On the face of it, these views seem very different. However many connectionists do not view their work as a challenge to classicism and some overtly support the classical picture. So-called implementational connectionists seek an accommodation between the two paradigms. They hold that the brain’s net implements a symbolic processor. True, the mind is a neural net; but it is also a symbolic processor at a higher and more abstract level of description. So the role for connectionist research according to the implementationalist is to discover how the machinery needed for symbolic processing can be forged from neural network materials, so that classical processing can be reduced to the neural network account.

It is interesting to note that distributed, rather than local representations on the hidden units are the natural products of connectionist training methods. The activation patterns that appear on the hidden units while NETtalk processes text serve as an example. Analysis reveals that the net learned to represent such categories as consonants and vowels, not by creating one unit active for consonants and another for vowels, but rather in developing two different characteristic patterns of activity across all the hidden units.


 since representations are coded in patterns rather than firings of individual units, relationships between representations are coded in the similarities and differences between these patterns.

such tasks as language and reasoning cannot be accomplished by associative methods alone and so connectionists are unlikely to match the performance of classical models at explaining these higher-level cognitive abilities. 

Systematicity may exist in connectionist architectures, but where it exists, it is no more than a lucky accident. The classical solution is much better, because in classical models, pervasive systematicity comes for free.

Folk psychology is the conceptual structure that we spontaneously apply to understanding and predicting human behavior. For example, knowing that John desires a beer and that he believes that there is one in the refrigerator allows us to explain why John just went into the kitchen. Such knowledge depends crucially on our ability to conceive of others as having desires and goals, plans for satisfying them, and beliefs to guide those plans. The idea that people have beliefs, plans and desires is a commonplace of ordinary life; but does it provide a faithful description of what is actually to be found in the brain?

Hume’s associationism was, first and foremost, a theory connecting how perceptions (“Impressions”) determined trains of thought (successions of “Ideas”). Hume’s empiricism, as enshrined in the Copy Principle,[5] demanded that there were no Ideas in the mind that were not first given in experience. For Hume, the principles of association constrained the functional role of Ideas once they were copied from Impressions: if Impressions IM1 and IM2 were associated in perception, then their corresponding Ideas, ID1 and ID2 would also become associated. In other words, the ordering of Ideas was determined by the ordering of the Impressions that caused the Ideas to arise.

Associative learning didn’t hit its stride until the work of Ivan Pavlov, which spurred the subsequent rise of the behaviorist movement in psychology. Pavlov introduced the concept of classical conditioning as a modernized version of associative learning.

This research culminated in Thorndike’s famous “Law of Effect” (1911), the first canonical psychological law of associationist learning. It asserted that responses that are accompanied by the organism feeling satisfied will, ceteris paribus, be more likely to be associated with the situation in which the behavior was executed,

**what all varieties should share with their historical predecessors is that associative learning is supposed to mirror the contingencies in the world without adding additional structure to them**

both Hume and Pavlov assumed that associative learning could be used to acquire associations between any contents, regardless of the types of contents they were. ... In that sense, the learning is domain general

saying that two concepts are associated amounts to saying that there is a reliable, psychologically basic causal relation that holds between them—the activation of one of the concepts causes the activation of the other

> Associative structures are most naturally contrasted with propositional structures. A pure associationist is opposed to propositional structures—strings of mental representations that express a proposition—because propositionally structured mental representations have structure over and above the mere associative bond between two concepts. Take, for example, the associative structure green/toucan. This structure does not predicate green onto toucan. If we know that a mind has an associative bond between green and toucan, then we know that activating one of those concepts leads to the activation of the other. A pure associative theory rules out predication, for propositional structures aren’t just strings of associations. “Association” (in associative structures) just denotes a causal relation among mental representations, whereas predication (roughly) expresses a relation between things in the world (or intentional contents that specify external relations). Saying that someone has an associative thought green/toucan tells you something about the causal and temporal sequences of the activation of concepts in one’s mind; saying that someone has the thought there is a green toucan tells you that a person is predicating greenness of a particular toucan (see Fodor 2003: 91–94, for an expansion of this point).

Associative transitions are transitions in thought that are not based on the logico-syntactic properties of thoughts. Rather, they are transitions in thought that occur based on the associative relations among the separate thoughts.

A computational inference might be one such as inferring you are a g from the thoughts if you are an f, then you are a g, and you are an f. However, an associative transition is just a stream of ideas that needn’t have any formal, or even rational, relation between them, such as the transition from this coffee shop is cold to russia should annex idaho, without there being any intervening thoughts. This transition could be subserved merely by one’s association of idaho and cold, or it could happen because the two thoughts have tended to co-occur in the past, and their close temporal proximity caused an association between the two thoughts to arise (or for many other reasons).

According to this taxonomy, talk of an “associative inference” (e.g., Anderson et al. 1994; Armstrong et al. 2012) is a borderline oxymoron. The easiest way to give sense to the idea of an associative inference is for it to involve transitions in thought that began because they were purely inferential (as understood by the computational theory of mind) but then became associated over time.

associative thinking across topics bolsters mood when compared to logical thinking on a single topic

Implementation can be seen at a representational (that is psychological) level of explanation, or at the neural level. A pure associationist picture would posit an associative implementation base at one, or both, of these levels.[26]

The most well-known associative instantiation base is a class of networks called Connectionist networks

[Argument]: representationalism or anti is not well defined. If I represent a cat as all of its atoms, where each atom is a symbol in CTM. Or if I represent a cat as many btoms, where in another world btoms are understood as building blocks of matter.