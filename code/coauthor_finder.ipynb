{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scholarly\n",
      "  Downloading scholarly-1.7.11-py3-none-any.whl.metadata (7.4 kB)\n",
      "Collecting arrow (from scholarly)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from scholarly) (4.12.3)\n",
      "Collecting bibtexparser (from scholarly)\n",
      "  Downloading bibtexparser-1.4.3.tar.gz (55 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting deprecated (from scholarly)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting fake-useragent (from scholarly)\n",
      "  Downloading fake_useragent-2.0.3-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting free-proxy (from scholarly)\n",
      "  Downloading free_proxy-1.1.3.tar.gz (5.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: httpx in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from scholarly) (0.27.0)\n",
      "Collecting python-dotenv (from scholarly)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: requests[socks] in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from scholarly) (2.32.3)\n",
      "Collecting selenium (from scholarly)\n",
      "  Downloading selenium-4.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting sphinx-rtd-theme (from scholarly)\n",
      "  Downloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: typing-extensions in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from scholarly) (4.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from arrow->scholarly) (2.9.0.post0)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow->scholarly)\n",
      "  Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from beautifulsoup4->scholarly) (2.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.3 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from bibtexparser->scholarly) (3.1.2)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from deprecated->scholarly) (1.14.1)\n",
      "Requirement already satisfied: lxml in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from free-proxy->scholarly) (5.3.0)\n",
      "Requirement already satisfied: anyio in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpx->scholarly) (4.6.2)\n",
      "Requirement already satisfied: certifi in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpx->scholarly) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpx->scholarly) (1.0.2)\n",
      "Requirement already satisfied: idna in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpx->scholarly) (3.7)\n",
      "Requirement already satisfied: sniffio in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpx->scholarly) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from httpcore==1.*->httpx->scholarly) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from requests[socks]->scholarly) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from requests[socks]->scholarly) (2.2.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from requests[socks]->scholarly) (1.7.1)\n",
      "Collecting trio~=0.17 (from selenium->scholarly)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium->scholarly)\n",
      "  Downloading trio_websocket-0.11.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from selenium->scholarly) (1.8.0)\n",
      "Collecting sphinx<9,>=6 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinx-8.1.3-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting docutils<0.22,>0.18 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading docutils-0.21.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from python-dateutil>=2.7.0->arrow->scholarly) (1.16.0)\n",
      "Collecting sphinxcontrib-applehelp>=1.0.7 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-devhelp>=1.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-htmlhelp>=2.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-jsmath>=1.0.1 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sphinxcontrib-qthelp>=1.0.6 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting sphinxcontrib-serializinghtml>=1.1.9 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: Jinja2>=3.1 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (3.1.4)\n",
      "Collecting Pygments>=2.17 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading pygments-2.19.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting snowballstemmer>=2.2 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading snowballstemmer-2.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting babel>=2.13 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting alabaster>=0.7.14 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading alabaster-1.0.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting imagesize>=1.3 (from sphinx<9,>=6->sphinx-rtd-theme->scholarly)\n",
      "  Downloading imagesize-1.4.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: packaging>=23.0 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from sphinx<9,>=6->sphinx-rtd-theme->scholarly) (24.1)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from trio~=0.17->selenium->scholarly) (24.2.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium->scholarly)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting outcome (from trio~=0.17->selenium->scholarly)\n",
      "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium->scholarly)\n",
      "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/yuwang/miniconda3/envs/versatile/lib/python3.11/site-packages (from Jinja2>=3.1->sphinx<9,>=6->sphinx-rtd-theme->scholarly) (2.1.3)\n",
      "Downloading scholarly-1.7.11-py3-none-any.whl (39 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading fake_useragent-2.0.3-py3-none-any.whl (201 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading selenium-4.28.1-py3-none-any.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m791.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinx_rtd_theme-3.0.2-py2.py3-none-any.whl (7.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading docutils-0.21.2-py3-none-any.whl (587 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.4/587.4 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sphinx-8.1.3-py3-none-any.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
      "Downloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.11.1-py3-none-any.whl (17 kB)\n",
      "Downloading types_python_dateutil-2.9.0.20241206-py3-none-any.whl (14 kB)\n",
      "Downloading alabaster-1.0.0-py3-none-any.whl (13 kB)\n",
      "Downloading babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)\n",
      "Downloading pygments-2.19.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)\n",
      "Downloading sphinxcontrib_applehelp-2.0.0-py3-none-any.whl (119 kB)\n",
      "Downloading sphinxcontrib_devhelp-2.0.0-py3-none-any.whl (82 kB)\n",
      "Downloading sphinxcontrib_htmlhelp-2.1.0-py3-none-any.whl (98 kB)\n",
      "Downloading sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)\n",
      "Downloading sphinxcontrib_qthelp-2.0.0-py3-none-any.whl (88 kB)\n",
      "Downloading sphinxcontrib_serializinghtml-2.0.0-py3-none-any.whl (92 kB)\n",
      "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Building wheels for collected packages: bibtexparser, free-proxy\n",
      "  Building wheel for bibtexparser (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bibtexparser: filename=bibtexparser-1.4.3-py3-none-any.whl size=43555 sha256=8f2176795fe84559214f18f2346d44800d3a9a069ea4de72f30e3e20df6cadfb\n",
      "  Stored in directory: /Users/yuwang/Library/Caches/pip/wheels/16/fb/76/306387739cf9d53b1c39b0c8aadbbb17dc05f256756d8fd915\n",
      "  Building wheel for free-proxy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for free-proxy: filename=free_proxy-1.1.3-py3-none-any.whl size=6096 sha256=995c0ac315bea9b31a53f0edeef7650d582b8acfb1d5317e53b71747d76eaf1a\n",
      "  Stored in directory: /Users/yuwang/Library/Caches/pip/wheels/9e/f8/90/1e74c4166b7fbb213260a35e83fac3119f5e390c8bddda8a37\n",
      "Successfully built bibtexparser free-proxy\n",
      "Installing collected packages: sortedcontainers, snowballstemmer, wsproto, types-python-dateutil, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, python-dotenv, Pygments, outcome, imagesize, fake-useragent, docutils, deprecated, bibtexparser, babel, alabaster, trio, sphinx, free-proxy, arrow, trio-websocket, sphinxcontrib-jquery, sphinx-rtd-theme, selenium, scholarly\n",
      "  Attempting uninstall: Pygments\n",
      "    Found existing installation: Pygments 2.15.1\n",
      "    Uninstalling Pygments-2.15.1:\n",
      "      Successfully uninstalled Pygments-2.15.1\n",
      "  Attempting uninstall: babel\n",
      "    Found existing installation: Babel 2.11.0\n",
      "    Uninstalling Babel-2.11.0:\n",
      "      Successfully uninstalled Babel-2.11.0\n",
      "Successfully installed Pygments-2.19.1 alabaster-1.0.0 arrow-1.3.0 babel-2.17.0 bibtexparser-1.4.3 deprecated-1.2.18 docutils-0.21.2 fake-useragent-2.0.3 free-proxy-1.1.3 imagesize-1.4.1 outcome-1.3.0.post0 python-dotenv-1.0.1 scholarly-1.7.11 selenium-4.28.1 snowballstemmer-2.2.0 sortedcontainers-2.4.0 sphinx-8.1.3 sphinx-rtd-theme-3.0.2 sphinxcontrib-applehelp-2.0.0 sphinxcontrib-devhelp-2.0.0 sphinxcontrib-htmlhelp-2.1.0 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-2.0.0 sphinxcontrib-serializinghtml-2.0.0 trio-0.29.0 trio-websocket-0.11.1 types-python-dateutil-2.9.0.20241206 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import ProxyGenerator\n",
    "\n",
    "# Set up a ProxyGenerator object to use free proxies\n",
    "# This needs to be done only once per session\n",
    "pg = ProxyGenerator()\n",
    "pg.FreeProxies()\n",
    "scholarly.use_proxy(pg)\n",
    "\n",
    "# Now search Google Scholar from behind a proxy\n",
    "search_query = scholarly.search_pubs('Perception of physical stability and center of mass of 3D objects')\n",
    "scholarly.pprint(next(search_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Retrieve and fill the author's profile using the scholar_id.\n",
    "    author = scholarly.search_author_id('GLnX3MkAAAAJ')\n",
    "    author = scholarly.fill(author)\n",
    "except Exception as e:\n",
    "    print(f\"Error retrieving author with ID {'GLnX3MkAAAAJ'}: {e}\")\n",
    "\n",
    "# Get the list of publications from the profile\n",
    "publications = author.get('publications', [])\n",
    "\n",
    "def get_year(pub):\n",
    "    # Attempt to extract the publication year; if not available, use 0.\n",
    "    try:\n",
    "        return int(pub['bib'].get('year', 0))\n",
    "    except Exception:\n",
    "        return 0\n",
    "\n",
    "# Sort publications by publication year in descending order (most recent first)\n",
    "sorted_pubs = sorted(publications, key=get_year, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'container_type': 'Publication',\n",
       " 'source': <PublicationSource.AUTHOR_PUBLICATION_ENTRY: 'AUTHOR_PUBLICATION_ENTRY'>,\n",
       " 'bib': {'title': 'Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback',\n",
       "  'pub_year': '2022',\n",
       "  'citation': 'arXiv preprint arXiv:2204.05862, 2022'},\n",
       " 'filled': False,\n",
       " 'author_pub_id': 'GLnX3MkAAAAJ:9yKSN-GCB0IC',\n",
       " 'num_citations': 1706,\n",
       " 'citedby_url': 'https://scholar.google.com/scholar?oi=bibs&hl=en&cites=11199782510491151350,3181880679113735441,4889875407025449859,14427135269327430373,4405664652634518466',\n",
       " 'cites_id': ['11199782510491151350',\n",
       "  '3181880679113735441',\n",
       "  '4889875407025449859',\n",
       "  '14427135269327430373',\n",
       "  '4405664652634518466']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pubs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback', 'pub_year': '2022', 'citation': 'arXiv preprint arXiv:2204.05862, 2022'}\n",
      "{'title': 'In-context Learning and Induction Heads', 'pub_year': '2022', 'citation': 'Transformer Circuits Thread, 2022'}\n",
      "{'title': 'A Mathematical Framework for Transformer Circuits', 'pub_year': '2021', 'citation': 'Transformer Circuits Thread, 2021'}\n",
      "{'title': 'Progress Measures For Grokking Via Mechanistic Interpretability', 'pub_year': '2023', 'citation': 'ICLR 2023 Spotlight, 2023'}\n",
      "{'title': 'Predictability and surprise in large generative models', 'pub_year': '2022', 'citation': 'Proceedings of the 2022 ACM Conference on Fairness, Accountability, and …, 2022'}\n",
      "Unique first and second authors from recent papers:\n"
     ]
    }
   ],
   "source": [
    "from scholarly import scholarly\n",
    "\n",
    "def get_first_and_second_authors(scholar_id, max_recent_papers_to_search=5):\n",
    "    \"\"\"\n",
    "    Given a scholar_id, fetch the scholar's profile, then from the most recent\n",
    "    `max_recent_papers_to_search` publications, extract the first and second authors\n",
    "    (only if the publication has at least 3 authors). Returns a non-repeating list of names.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve and fill the author's profile using the scholar_id.\n",
    "        author = scholarly.search_author_id(scholar_id)\n",
    "        author = scholarly.fill(author)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving author with ID {scholar_id}: {e}\")\n",
    "        return []\n",
    "\n",
    "    # Get the list of publications from the profile\n",
    "    publications = author.get('publications', [])\n",
    "    \n",
    "    def get_year(pub):\n",
    "        # Attempt to extract the publication year; if not available, use 0.\n",
    "        try:\n",
    "            return int(pub['bib'].get('year', 0))\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    # Sort publications by publication year in descending order (most recent first)\n",
    "    sorted_pubs = sorted(publications, key=get_year, reverse=True)\n",
    "    print(sorted_pubs)\n",
    "    # Limit to the max_recent_papers_to_search number of publications\n",
    "    selected_pubs = sorted_pubs[:max_recent_papers_to_search]\n",
    "\n",
    "    authors_set = set()  # Use a set to avoid duplicates\n",
    "\n",
    "    for pub in selected_pubs:\n",
    "        # Ensure the publication has an 'author' field in its bibliography details\n",
    "        bib = pub.get('bib', {})\n",
    "        if 'author' in bib:\n",
    "            # The authors string is expected to be a comma-separated list of names.\n",
    "            authors_list = [a.strip() for a in bib['author'].split(',')]\n",
    "            if len(authors_list) >= 3:\n",
    "                # Extract the first and second authors and add to the set.\n",
    "                authors_set.add(authors_list[0])\n",
    "                authors_set.add(authors_list[1])\n",
    "    \n",
    "    # Convert the set to a list before returning\n",
    "    return list(authors_set)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Replace this with a valid Google Scholar ID.\n",
    "    example_scholar_id = \"GLnX3MkAAAAJ\"\n",
    "    max_recent = 5  # Set the number of recent papers to search\n",
    "\n",
    "    result_authors = get_first_and_second_authors(example_scholar_id, max_recent)\n",
    "    print(\"Unique first and second authors from recent papers:\")\n",
    "    for author_name in result_authors:\n",
    "        print(author_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for 'Javier Ferrando' ...\n",
      "  Match found: Javier Ferrando (ID: ZNsw8ZUAAAAJ)\n",
      "\n",
      "Matching Scholar IDs: ['ZNsw8ZUAAAAJ']\n",
      "Fetching details for scholar_id ZNsw8ZUAAAAJ ...\n",
      "\n",
      "CSV file created: scholars.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "scholar_names = ['Javier Ferrando', \n",
    "                #  'Oscar Obeso', \n",
    "                #  'Senthooran Rajamanoharan'\n",
    "                 ]\n",
    "\n",
    "list_field_to_match = [\n",
    "    'Machine Learning',\n",
    "    'Deep Learning',\n",
    "    'Natural Language Processing',' Interpretability','Mechanistic Interpretability'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Helper Functions\n",
    "# -----------------------------\n",
    "def matches_field(interests, fields):\n",
    "    \"\"\"\n",
    "    Check if any of the research interests contains one of the fields (case-insensitive).\n",
    "    \"\"\"\n",
    "    for field in fields:\n",
    "        for interest in interests:\n",
    "            if field.lower() in interest.lower():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def get_matching_scholar_ids(scholar_names, list_field_to_match):\n",
    "    \"\"\"\n",
    "    For each scholar name, search Google Scholar, fill in details,\n",
    "    and if any research interest matches one of the fields, return the scholar_id.\n",
    "    \"\"\"\n",
    "    matching_ids = []\n",
    "    \n",
    "    for name in scholar_names:\n",
    "        print(f\"Searching for '{name}' ...\")\n",
    "        search_query = scholarly.search_author(name)\n",
    "        for author in search_query:\n",
    "            try:\n",
    "                # Fill in the full profile details for this candidate\n",
    "                author_filled = scholarly.fill(author)\n",
    "            except Exception as e:\n",
    "                print(f\"  Error fetching details for '{name}': {e}\")\n",
    "                continue\n",
    "\n",
    "            interests = author_filled.get('interests', [])\n",
    "            if interests and matches_field(interests, list_field_to_match):\n",
    "                scholar_id = author_filled.get('scholar_id')\n",
    "                if scholar_id:\n",
    "                    matching_ids.append(scholar_id)\n",
    "                    print(f\"  Match found: {author_filled.get('name', 'Unknown')} (ID: {scholar_id})\")\n",
    "        print()  # Blank line for readability between names\n",
    "    \n",
    "    return matching_ids\n",
    "\n",
    "def get_recent_papers(author, num_papers=3):\n",
    "    \"\"\"\n",
    "    Extract the titles of the most recent `num_papers` from the author's publications.\n",
    "    Publications are sorted by publication year (if available).\n",
    "    \"\"\"\n",
    "    publications = author.get('publications', [])\n",
    "    \n",
    "    # Helper to extract year; if missing or invalid, use 0 so they sort last.\n",
    "    def get_year(pub):\n",
    "        try:\n",
    "            return int(pub['bib'].get('year', 0))\n",
    "        except Exception:\n",
    "            return 0\n",
    "\n",
    "    # Sort publications by year (most recent first)\n",
    "    sorted_pubs = sorted(publications, key=get_year, reverse=True)\n",
    "    # Extract the titles of the top `num_papers` publications\n",
    "    recent_papers = [pub['bib'].get('title', 'N/A') for pub in sorted_pubs[:num_papers]]\n",
    "    return recent_papers\n",
    "\n",
    "def create_csv(scholar_ids, csv_filename=\"scholars.csv\"):\n",
    "    \"\"\"\n",
    "    For each scholar_id, fetch the full profile details and extract:\n",
    "      - Name\n",
    "      - Citation count\n",
    "      - Affiliation\n",
    "      - Most recent 3 papers (titles)\n",
    "    Then sort all records by citation count (ascending) and write them to a CSV file.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for scholar_id in scholar_ids:\n",
    "        print(f\"Fetching details for scholar_id {scholar_id} ...\")\n",
    "        try:\n",
    "            # Retrieve the author's profile by their scholar_id\n",
    "            author = scholarly.search_author_id(scholar_id)\n",
    "            author = scholarly.fill(author)\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving author with id {scholar_id}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        name = author.get('name', 'N/A')\n",
    "        affiliation = author.get('affiliation', 'N/A')\n",
    "        citations = author.get('citedby', 0)\n",
    "        recent_papers = get_recent_papers(author)\n",
    "        # Join the recent papers into a single string (separated by semicolons)\n",
    "        recent_papers_str = \"; \".join(recent_papers)\n",
    "        \n",
    "        data.append({\n",
    "            \"Name\": name,\n",
    "            \"Citations\": citations,\n",
    "            \"Affiliation\": affiliation,\n",
    "            \"Most Recent 3 Papers\": recent_papers_str\n",
    "        })\n",
    "    \n",
    "    # Sort the data by citation count (ascending: lowest to highest)\n",
    "    data_sorted = sorted(data, key=lambda x: x[\"Citations\"])\n",
    "    \n",
    "    # Write the sorted data to a CSV file\n",
    "    fieldnames = [\"Name\", \"Citations\", \"Affiliation\", \"Most Recent 3 Papers\"]\n",
    "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csvfile:\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for row in data_sorted:\n",
    "            writer.writerow(row)\n",
    "    \n",
    "    print(f\"\\nCSV file created: {csv_filename}\")\n",
    "\n",
    "# -----------------------------\n",
    "# Main Execution\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Get matching scholar IDs based on names and research interests\n",
    "    matching_ids = get_matching_scholar_ids(scholar_names, list_field_to_match)\n",
    "    print(\"Matching Scholar IDs:\", matching_ids)\n",
    "    \n",
    "    # Step 2: Fetch full profiles, sort by citation count, and write to CSV\n",
    "    create_csv(matching_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "versatile",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
