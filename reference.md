# By Subject
---
# Economy/Finance
See log 2024.10.5

> No one ever made a decision because of a number. they need a story.  --Daniel Kahneman

## Traditional
### Valuation
- [MIT Valuation class](https://www.youtube.com/watch?v=tjNJx2244Lc&list=PLUkh9m2BorqmtIQKZ1jv3uuZDM_bQIICg)

### Investopedia
- Dow theory: 

# Quant
## Crypto Specific
### Data Source
- [yahoo finance intro](https://algotrading101.com/learn/yfinance-guide/)
- [coin gecko](https://www.coingecko.com/learn/python-query-coingecko-api)
- [py crypto compare](https://github.com/lagerfeuer/cryptocompare?tab=readme-ov-file)
- [py coinbase](https://github.com/David-Woroniuk/Historic_Crypto)

### Tutorials
- [ether python bot](https://medium.com/@crjameson)
- [ether sandwitch](https://medium.com/@rjaloudi)
- [radium bot github search](https://github.com/topics/raydium-bot?l=python&o=desc&s=stars)
- https://chainstack.com/solana-python-tutorial-querying-and-analyzing-data-from-raydium/
- https://www.youtube.com/@moondevonyt

## General
### Backtesting
- [looks nice library](https://github.com/polakowo/vectorbt)

### Recources
- book (Quantitative Finance and Risk Management: A Physicist's Approach)
- book (Paul Wilmott Introduces Quantitative Finance): read this before the Physicist's Approach book, this is from intro to finance to deep stuff
- book (also by Paul Wilmott, The mathematics of financial derivatives)
- book (brownian motion calculus)
- collections (https://github.com/PlamenStilyianov/FinMathematics/tree/master)
- [science researcher, search "The Capital Asset Pricing Model" and above includes many quant modeling](https://gregorygundersen.com/blog/)
- [python all kinds of stock code](https://medium.com/@crisvelasquez)
- [algotrading sub wiki](https://www.reddit.com/r/algotrading/wiki/index/#wiki_strategy)



# Physics
## Mechanics
[taylor solutions](https://stemjock.com/taylorcm.htm?srsltid=AfmBOopdOKiKrV92Aoo75qMnO8lXN9gmUDkQeaXi0cbGXHgBFPQYZqV0)
### Coordinate Systems
- [some graphs of functions in polar coordinate](https://ximera.osu.edu/mooculus/calculus2/introductionToPolarCoordinates/digInIntroductionToPolarCoordinates)
### Angular Momentum
- [comprehensive guide to why we use it](https://math.stackexchange.com/questions/349907/cross-product-intuition)
### Lagrangian
- [differential intro with entropy example](https://mbernste.github.io/posts/functionals/)
- [good intro euler-langrange](https://gregorygundersen.com/blog/2020/05/10/euler-lagrange/)
- https://profoundphysics.com/constraints-in-lagrangian-mechanics/
- https://profoundphysics.com/lagrangian-vs-newtonian-mechanics-the-key-differences/


## Chaos
### General Material
- for overview, use Taylor, classical mechanics.
### Fluid
- [](https://ciechanow.ski/)



## Light
### Interference
[hologram](https://www.youtube.com/watch?v=EmKQsSDlaa4)

# Math
## Unclassified
### Convolution
- [intro convolution with cookie example](https://www.youtube.com/watch?v=aEGboJxmq-w)

## General
### Math books to read
https://www.3blue1brown.com/blog/book-recommendations

## Basic Analysis
### Calculus
- [derivative with Fermat visual 3b1b style](https://www.reddit.com/r/math/comments/llsw8a/calculating_slope_without_derivativeslimits/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)
- [potentially useful for real analysis](https://www.reddit.com/r/learnmath/comments/8ipe0u/comment/dytvvkt/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)
- [notes with graphs for intro real analysis](https://math.fel.cvut.cz/en/mt/pagee1.htm)

### Elementary Functions
Conic functions:
![](/images/conic.png)
- [Feynman why orbits are elipse](https://www.youtube.com/watch?v=xdIjYBtnvZU)
- [why eclipse in conic section 3b1b](https://www.youtube.com/watch?v=pQa_tWZmlGs)
- [parabola animation](https://www.reddit.com/r/3Blue1Brown/comments/ddygcw/manim_animation_parabola/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)
- [shadows and sun and hyperbola](https://www.youtube.com/watch?v=TfoTBKSIzlM)
- [intro hyperbola](https://www.youtube.com/watch?v=HnHnEnkZpJA)
- [Hyperpolic functions potentially quantum physics with philosophical isights](https://www.youtube.com/watch?v=WL8l16SWp7g&t)

Log and e: 
- [log visual, antishapeshifter, 1/x](https://www.youtube.com/watch?v=G0Fa5Zl-Z3c)

## Functional Analysis
- [23 pages textbook starting from Fourier](https://courses.mai.liu.se/GU/TATM85/FA-history.pdf)

## Transforms
### Fourier
- [a good general introduction for advanced learner](https://databookuw.com/)
- ${\displaystyle {\widehat {f}}(\xi )=\int _{-\infty }^{\infty }f(x)\ e^{-i2\pi \xi x}\,dx.}$
- [Euler's formula with introductory group theory](https://www.youtube.com/watch?v=mvmuCPvRoWQ)
- [Fourier transform as linear algebra](https://www.youtube.com/watch?v=7Vma1G2p6A8)
- $\mathcal{F}\left\{\frac{d^n}{dt^n} f(t)\right\} = (i \omega)^n F(\omega)$
- $\frac{d}{d\omega} F(\omega) = -i \int_{-\infty}^{\infty} t f(t) e^{-i \omega t} \,$ which is Fourier transform of -itf(t), ie: $\frac{d}{d\omega} F(\omega) = \mathcal{F}\{ -i t f(t) \}$

### Laplace
- [high level intuition on laplace](https://qr.ae/p2HJrb)
- [great outline](https://math.stackexchange.com/questions/3190961/how-is-the-laplace-transform-a-change-of-basis/3537213#3537213) and https://math.stackexchange.com/questions/428408/physical-interpretation-of-laplace-transforms

### Discrete Fourier
- [DFT reducible](https://www.youtube.com/watch?v=yYEMxqreA10)
- [FFT reducible](https://www.youtube.com/watch?v=h7apO7q16V0)

### Z

## *Transforms in Engineering
### Window Function
- a mathematical function that is zero-valued outside of some chosen interval.
- The reasons for examining segments of a longer function include detection of transient events and time-averaging of frequency spectra
- Hann window
- Gaussian window

### Windowed Fourier Transform
Definition:
- Forward: ${\displaystyle \mathbf {STFT} \{x(t)\}(\tau ,\omega )\equiv X(\tau ,\omega )=\int _{-\infty }^{\infty }x(t)w(t-\tau )e^{-i\omega t}\,dt}$
- Inverse: 
### Wavelet Transform
Definition:
- ${\displaystyle X_{w}(a,b)={\frac {1}{|a|^{1/2}}}\int _{-\infty }^{\infty }x(t){\overline {\psi }}\left({\frac {t-b}{a}}\right)\,\mathrm {d} t}$
- a is scale, b is translation, so a essentially represents frequency (1/f). 
- if $\psi = e^{\frac{it}{a}}$ then it's basically the same as fourier transform.
- psi is called the mother wavelet and the scaled and translated versions are daughter wavelets
- Inverse: ${\displaystyle x(t)=C_{\psi }^{-1}\int _{0}^{\infty }\int _{-\infty }^{\infty }X_{w}(a,b){\frac {1}{|a|^{1/2}}}{\tilde {\psi }}\left({\frac {t-b}{a}}\right)\,\mathrm {d} b\ {\frac {\mathrm {d} a}{a^{2}}}}$
- inverse is beyond understanding for now

Introduction:
- [very good intro on frequency analysis and wt from climate background](https://www.jstor.org/stable/26232616)
- [great post of birth data with code and intepretation](https://www.kaggle.com/code/asauve/a-gentle-introduction-to-wavelet-for-data-analysis)

Applications:
- [dwt dnn dow paper with preliminary](https://www.iccs-meeting.org/archive/iccs2018/papers/108610377.pdf)
- [dwt and nn predict DOW blog](https://medium.com/@crisvelasquez/riding-the-waves-of-stock-prices-with-wavelet-transform-signals-in-python-e2e81217f9fd)

## Group Theory
- [Euler's formula with introductory group theory](https://www.youtube.com/watch?v=mvmuCPvRoWQ)

## Linear Algebra
- [visual matrices general](https://www.youtube.com/watch?v=4csuTO7UTMo)
- [visual Gauss elimination](https://www.youtube.com/watch?v=bnC848ie16Q)

### Determinant
Definition:

History:
- A determinant was originally defined as a property of a system of linear equations. 
- Given: $\begin{pmatrix} a & b \\ c & d \end{pmatrix} \begin{pmatrix} x_1 \\x_2\end{pmatrix}=\begin{pmatrix}y_1 \\y_2\end{pmatrix}$, $x_2 = \frac{y_1 - \frac{a}{c} y_2}{b - \frac{a d}{c}}$ and has solution when $b - \frac{a d}{c} \neq 0$ or when ad=cb

Properties:
- if ad=cb, $x_2 = \frac{y_1 - \frac{a}{c} y_2}{b - \frac{a d}{c}}$ is undefined unless y1=y2=0, in which case any x can be anything. 

## Optimization
### Linear Programming
- [great simple intro with graphs](https://medium.com/@mengsaylms/a-brief-introduction-to-linear-programming-2107e769a1fe)

# Statistics and Probability
See Log 2024.10.12 for overview

## Measure Theory
- [intuitive intro](https://mbernste.github.io/posts/measure_theory_3/)
- [definition based posts](https://random-walks.org/intro.html)
### General Definitions
- $\sigma$-algebra:
a collection of subsets of a given set that satisfies the following properties:
    1. Contains the empty set
    2. Closure under complement
    3. Closure under countable unions
    - This also implies closure under set intersections, differences, and symmetric differences

- Measure $\mu: \mathcal{F} \to [0, \infty]$
    1. $\mu(\emptyset) = 0$
    2. $\mu\left( \bigcup_{n=1}^{\infty} A_n \right) = \sum_{n=1}^{\infty} \mu(A_n)$
- Measurable Space $(\Omega, \mathcal{F})$
- Measure Space $(\Omega, \mathcal{F}, \mu)$
- Measurable Function: Given measurable spaces $(F, \mathcal{F})$ and $(H, \mathcal{H})$ a function f: F->H is a measurable function iff $\forall A \in \mathcal{H}, f^{-1}(A) \in \mathcal{F}$, note that $f^{-1}(A) = \{ f^{-1}(y) \mid y \in A \}$
- Simple function: 
- Lebesgue integral: For the Lebesgue integral, a rectangle is formed for each value in the function’s codomain

### Probability Measure
- Outcome space:
- Event space (sigma-algebra of outcome space)
- A probability space $(\Omega, E, P)$ is a measure space where $P(\Omega)=1$
- Random variable: 
    - $X: \Omega \to R$. As a measurable function $\forall A \in \mathcal{R}, X^{-1}(A) \in E$.
    - ${\displaystyle P(X=a):=P(X^{-1}(\{a\}))=P(e)=P(w|X(w)=a)}$ for example: ${\displaystyle P(score>60)=P\{X^{-1}((60, 100])\}=P(w|60<X(w)<=100)}$
- Probability mass function: ${\displaystyle p_{X}(x)=P(X=x)}$
- Probability density function:
    - s
- Expectation: $E(X) := \int_{\Omega} X \ dP$


## Common Techniques
### Basic Transformations
Normalization:

Whitening:
- https://gwpy.github.io/docs/stable/examples/timeseries/whiten/

### Source/Latent Separation
There are source S=[s1(t), s2(t), ...], and observaton X=[x1(t), x2(t), ...]. X=AS. Now you want S from X. S=BX, you want B which is inverse of A.

**PCA**:
principal components constitute an orthonormal basis in which different individual dimensions of the data are linearly uncorrelated. PCA-based dimensionality reduction tends to minimize that information loss. Maximizes variance (second-order statistics)
- [PCA visual](https://setosa.io/ev/principal-component-analysis/)

**ICA**: Minimization of mutual information and Maximization of non-Gaussianity (higher-order statistics)
- [ICA very comprehensive and semi rigorous tutorial paper](https://www.cs.jhu.edu/~ayuille/courses/Stat161-261-Spring14/HyvO00-icatut.pdf): want to find independent components->want non-gaussian sources->opitmize non-gaussianity with kurtosis and negentropy
- [ica intro short no proof eeg](https://loonylabs.org/2021/06/03/intro-to-ica/): ![](/images/pca-vs-ica-highlighted.png)



### ANOVA

### Detection Theory
Sensitivity index (d'):
- separation between means: ${d'={\frac {\left\vert \mu _{a}-\mu _{b}\right\vert }{\sigma }}}$
- measures a participant's ability to distinguish between the presence (signal) and absence (noise) of a stimulus. d' = Z(hit rate) - Z(false alarm rate) where Z means z-score for the probability. A higher d' means better sensitivity

Criterion score (d):
- c = -0.5 × [Z(hit rate) + Z(false alarm rate)]
- c measures the participant's decision threshold or bias—how likely they are to say "Yes, the signal is present" regardless of whether it's actually there.
- A low criterion means they are liberal and tend to say "Yes" more often, leading to more hits but also more false alarms.



## Distributions
### Basic
- [great interactive multivariate Gaussian intro](https://distill.pub/2019/visual-exploration-gaussian-processes/): covariance matrix off diagnal values is the slope; Gaussian distributions are closed under conditioning (Bayesian) and marginalization ![](/images/2-variate-gaussian.png)

## Time Series 
### Basic Models
Gaussian Process (infinite dimensional Gaussian distribution, zero mean): ![](/images/gp-cond.png)
- [best intro to gaussian process](https://thegradient.pub/gaussian-process-not-quite-for-dummies/)
- [deeper interactive visual Gaussian process](https://distill.pub/2019/visual-exploration-gaussian-processes/):  ![](/images/gp-kernels.png)
- [GP python code from scratch and packages](https://domino.ai/blog/fitting-gaussian-process-models-python)
- [time series forecasting tutorial paper 26 pages](https://www.robots.ox.ac.uk/~sjrob/Pubs/Phil.%20Trans.%20R.%20Soc.%20A-2013-Roberts-.pdf)
- [interactive gp online](https://www.tmpl.fi/gp/)
- [ultimate guide with visual interaction and derivation and application](https://infallible-thompson-49de36.netlify.app/)

### Applications
- [comprehensive book on data processing UW professor](https://databookuw.com/)
- [comprehensive book on forecasting](https://otexts.com/fpp2)
- [STL](https://www.statsmodels.org/stable/examples/notebooks/generated/stl_decomposition.html): ![](/images/stl.png)

## Probability Theory
### Moments
- Raw moment about c: ${\displaystyle \mu _{n}=\int _{-\infty }^{\infty }(x-c)^{n}\,f(x)\,\mathrm {d} x.}$
- Central moment: ${\displaystyle \mu _{n}= {E} \left[(X- {E} [X])^{n}\right]=\int _{-\infty }^{+\infty }(x-\mu )^{n}f(x)\,\mathrm {d} x.}$
- Normalized/standard moment (n-th central moment divided by σ^n): ${\displaystyle {\frac {\mu _{n}}{\sigma ^{n}}}={\frac { {E} \left[(X-\mu )^{n}\right]}{\sigma ^{n}}}={\frac { {E} \left[(X-\mu )^{n}\right]}{ {E} \left[(X-\mu )^{2}\right]^{\frac {n}{2}}}}.}$

Common moments:
- Mean mu: first raw moment
- Variance: second central moment
- Skewness gamma: standardized third central moment. Left skewed distributions (the tail of the distribution is longer on the left) will have a negative skewness.
- Kurtosis kapa: standardized fourth central moment. measure of the heaviness of the tail

### Characteristic Function
- ${\displaystyle \phi_X(t) = \mathbb{E}[e^{itX}] = \int_{-\infty}^{\infty} e^{itx} f_X(x) \, dx}$

Expectation: 
- ${\displaystyle \frac{d\phi_X(t)}{dt} = i\int_{-\infty}^{\infty} xe^{itx} f_X(x) \, dx}$
- ${\displaystyle \frac{d\phi_X(0)}{dt} = i\int_{-\infty}^{\infty} x f_X(x) \, dx=iE[X]}$ 
- Note that since X is real valued, its fourier transform is conjugate symmetric, so the derivative at 0 is 0 for real component, but there's a shift in phase if derivative is non 0 in complex axis, the shift corresponds to the shift of center of mass of the distribution, ie, expectation.

Variance: 
- $\frac{d^2\phi_X(t)}{dt^2} = -\int_{-\infty}^{\infty} x^2e^{itx} f_X(x) \, dx$
- $\frac{d^2\phi_X(0)}{dt^2} = -\int_{-\infty}^{\infty} x^2 f_X(x) dx=-E[X^2]$
- $\text{Var}(X) = \mathbb{E}[X^2] - (\mathbb{E}[X])^2$
- The second derivative is a non positive real number. When it's 0, the original distribution is delta, and it's fourier transform is 1, which has all derivatives 0. The more negative it is, the more spiky the transform/power at 0.

In general: $\frac{d^k\phi_X(0)}{dt^k} = i^kE[X^k]$

- Relating to general FT, $\frac{d}{d\omega} F(\omega) = -i \int_{-\infty}^{\infty} t f(t) e^{-i \omega t} \,$ which is Fourier transform of -itf(t), ie: $\frac{d}{d\omega} F(\omega) = \mathcal{F}\{ -i t f(t) \}$

Taylor expansion: 
- $\phi(k) = \int_{-\infty}^{\infty} p(x) e^{ikx} \, dx = \int_{-\infty}^{\infty} p(x) \left( 1 + ikx - \frac{k^2x^2}{2} + \dots \right)= 1 + ik \mathbb{E}[x] - \frac{k^2}{2} \mathbb{E}[x^2] + \dots$
- Intuition: from one perspective, if you don't know about the concept of mean or variance etc, Taylor of Fourier of distribution gives approximation of the distribution. Taylor is local. Fourier encodes frequency. So Taylor of Fourier near 0 is good at low frequency. 

### Moment Generating Function (MGF)
Definition:
- $M_X(t) = \mathbb{E}[e^{tX}]= \int_{-\infty}^{\infty} e^{tx} f_X(x) \, dx$
- cf: $\phi_X(t) = \mathbb{E}[e^{itX}]$. 
- Relation to CF: M(it)=phi(t) or $M_X(t) = \phi_X(-it)$

Property:
- Generating moments: $\frac{d^n M_X(t)}{dt^n} \bigg|_{t=0} = \mathbb{E}[X^n]$
- Sum of RVs: since convolution becomes multiplication after Fourier transform, summing RVs becomes multiplication of their MGFs. $M_{S_n}(t) = \mathbb{E}\left[e^{t S_n}\right] = \mathbb{E}\left[e^{t \sum_{i=1}^{n} X_i}\right].$
- Normal distribution: $f_X(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}}.$ -> $M_X(t) = \int_{-\infty}^{\infty} e^{tx} \cdot \frac{1}{\sqrt{2\pi}} e^{-\frac{x^2}{2}} \, dx = \frac{1}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-\frac{1}{2}(x^2 - 2tx)} \, dx = \frac{e^{\frac{t^2}{2}}}{\sqrt{2\pi}} \int_{-\infty}^{\infty} e^{-\frac{(x - t)^2}{2}} \, dx.$  The thing inside the integral is gaussian. So $M_X(t) = e^{\frac{t^2}{2}}.$

Taylor: 
- $M_X(t) = \mathbb{E}\left[ e^{tX} \right] = \mathbb{E}\left[ 1 + tX + \frac{t^2 X^2}{2!} + \frac{t^3 X^3}{3!} + \cdots \right]$

CLT:
- Let $Y_i = \frac{X_i - \mu}{\sigma}$, $S_n = \frac{1}{\sqrt{n}} \sum_{i=1}^{n} Y_i$
- $M_{S_n}(t) = \mathbb{E}\left[e^{t S_n}\right] = \mathbb{E}\left[e^{\frac{t}{\sqrt{n}} \sum_{i=1}^{n} Y_i}\right]=\left( \mathbb{E}\left[e^{\frac{t}{\sqrt{n}} Y_1}\right] \right)^n = \left( M_{Y_1}\left( \frac{t}{\sqrt{n}} \right) \right)^n.$
- $M_{Y_1}\left( \frac{t}{\sqrt{n}} \right) \approx 1 + \frac{t^2}{2n} + o\left( \frac{1}{n} \right).$
- $M_{S_n}(t) = \left( 1 + \frac{t^2}{2n} + o\left( \frac{1}{n} \right) \right)^n$. Note this crucial step where the higher order moments/higher frequency components of the original distribution, no matter what it is, diminish under the n exponential.
- $\left( 1 + \frac{t^2}{2n} \right)^n \approx \exp\left( \frac{t^2}{2} \right) \quad \text{as } n \to \infty.$

Resources:
- [post with visuals](https://gregorygundersen.com/blog/2020/04/11/moments/)

## General Resoures
### Books
### Website
- [](https://random-walks.org/)


# Information Theory
## Concepts
### Entropy

> Note that ln(0.1x) = ln(x)+ln(0.1), ln(x)=ln(0.1x)+2.3 Therefore 0.1x is much smaller than ln(0.1x)



# Cognitiive
## Embodied
- [time representation embodied in space](https://www.sciencedirect.com/science/article/pii/S001002770700087X): asymetrical relatiionship (lightyear); clever expriments (growing lines with misleading duration-displacement relatoinship)


# Neuro
## EEG
### Classification
Traditional:
- [eeg to emotion with traditional processing](https://bcmi.sjtu.edu.cn/~blu/papers/2014/2.pdf)
- [SSVEP](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640776/): 60 characters/min
- [p300 speller](https://ieeexplore.ieee.org/document/1454155)
- [eeg to color with muse 2](https://arxiv.org/pdf/2008.07092)

DL:
- [hands on eeg to 4 words](https://justlv.medium.com/using-ai-to-read-your-thoughts-with-keras-and-an-eeg-sensor-167ace32e84a)
- [BELT: pretrained eeg encoder SOTA?](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10649644)
- [more nuanced improvement of above, same PI](https://arxiv.org/pdf/2408.04679)
- [eeg to robot control, same PI](https://arxiv.org/pdf/2410.02141)
- [transformer eeg to open text](https://arxiv.org/pdf/2112.02690): ![](/images/eeg-to-text-res.png)
- [diffusion eeg to image](https://arxiv.org/pdf/2410.02780v1)
- [recreating what's seen eeg to text coder to diffusion](https://arxiv.org/abs/2309.07149)
- [eegmmidb with NN and application in typing](https://arxiv.org/pdf/1709.08820): classifying 4 action intents. 7 characters/min for typing app.

### Spectrum Analysis
Alpha:
- [speed of alpha predicts visual temporal resolution](https://doi.org/10.1016/j.cub.2015.10.007): 

## MRI
### Classification
- [mri LLM to sentence from imagined or perceived sentence or video](https://www.nature.com/articles/s41593-023-01304-9)

## Theory of Learning/Memory
- [neural reuse](https://pubmed.ncbi.nlm.nih.gov/20964882/)

## Computational
### Introduction
- [advanced lecture](https://www.cns.nyu.edu/~rinzel/CMNSS10/)
- [sources?](https://www.cns.nyu.edu/~eero/teaching.html)

## Anatomical
### Mapping
- [neuronal wiring diagram of a complete fly brain](https://www.nature.com/immersive/d42859-024-00053-4/index.html)

## Frohlich lab onboarding/biomedical research involving human
### Safety Plans
- [SV](https://ehs.cloudapps.unc.edu/LabSafetyPlan/Controller?mode=processViewPlan&id=202416216)
- [MEJ](https://ehs.cloudapps.unc.edu/LabSafetyPlan/Controller?mode=processViewPlan&id=202416190)
### IRB training
- belmont report: 1. respect for persons (informed consent, protection of vulnarable groups) 2. beneficence (no harm, maximize benefit and minimize harm) 3. justice (fair distribution of benefits and burden)
![](/images/belmont.png)

### Responsible Research Conduct (RRC)
- Misonduct: Fabrication, Falsification, Plagirism
- Authorship
- Mentor-Mentee relationship building
- Data management
- Peer review
- Animal study
- Conflicts of Interest and Commitment
- Collaborative Research, patent, company and national fund
- human study, Common Rule

### UNC EHS https://ehs.unc.edu/training/orientation/clinic/
- Tubercolosis, transmission, development, skin test and treatment
- HIV, HAV (Hepatitis A), HBV, HCV
- fire
- biohazard, specimens, medial wastes, exposure control
- personal protetive equipments
- needle
- chemicals, distinct hazard and labeling

### COLUMBIA-SUICIDE SEVERITY RATING SCALE (C-SSRS)
- SUICIDAL IDEATION
- Actual Attempt:
A *potentially* self-injurious act committed with at least *some wish* to die, as a result of act. 

### GCP (good clinical practice) for Clinical Trials with Investigational Drugs, Biologics and Devices
- belmont report
- International Conference for Harmonisation->International Council for Harmonisation: ICH is an attempt to streamline the process for developing and marketing new drugs internationally.
- process for drug development. Investigational New Drug (IND). New drug applications. 
![](/images/IND-1.jpg)
![](/images/IND-2.jpg)
- Guideline for Good Clinical Practice (GCP) or ICH E6; “Clinical trials should be conducted in accordance with the ethical principles that have their origin in the Declaration of Helsinki, and that are consistent with GCP and the applicable regulatory requirement(s).
- obligations of a sponsor-investigator
- usage of investigational new drugs
- informed consent
- audits and inspections
- Adverse Events

- devices, significant risk device, class I, II, III; 510(k) (Premarket Notification), PMA (Premarket Approval), Investigational Device Exemption application (IDE)
- investigator obligations,Contract Research Organization (CRO)


## Tools
### EEG Streaming
- [openvibe](https://openvibe.inria.fr/discover/)

### General Data Streaming
- LSL: server based, the outlet starts multiple TCP and UDP servers and inlet requents stream

### Physiological data processing
Software:
- NFBLab
- MNE
- https://www.neuroexplorer.com/
Suggestions:
- https://sccn.ucsd.edu/wiki/Makoto's_preprocessing_pipeline
- [labeling independent compoennts from eeg (diipole)](https://labeling.ucsd.edu/tutorial/labels): ![](/images/IC-labeling.png)


### Dataset
- [eegmmidb: eeg data for real and imagined hand and foot control based on 4 stimulus directions](https://archive.physionet.org/pn4/eegmmidb/)
- [ZuCo: eeg and gaze data when reading texts](https://arxiv.org/abs/1912.00903)

- [P300 EEG data](https://www.nature.com/articles/s41597-022-01509-w)

## Anatomy
### Videos
- [100 MICRO MRI](https://www.youtube.com/watch?v=I0fjPyk1eHM&list=PLlL7CEMX5bxzl1TqkJRK3pMV4Ax6By4bN&index=6)

## Unclassified
- [llm to predict neuroscience research result and help with direction](https://braingpt.org/)

## Logistics
### Potential Research
- https://enyanglab.org/
- https://blender.cs.illinois.edu/publications/

# Language
## Latin
- [meter](https://hypotactic.com/latin/index.html?Use_Id=met1)
### Metamorphoses
- [sing with lyre](https://www.youtube.com/watch?v=UlfRPgL2MXg)
- [meter read](https://www.youtube.com/watch?v=FBwwNXbaznQ&t=48s)

# Health
## Top Hat
- VO2max: maximum liter of O2 per minute
- Aerobic vs anaerobic: Fats, carbohydrates and proteins can be used for fuel during aerobic metabolism; only carbohydrates in anaerobic and without oxygen
- \>=5days/week of moderate intensity exercise for 30m/d for an accumulated total of 150 minutes or more of exercise per week
- moderate intensity exercises are estimated at 50-70% of your Max Heart Rate
- 3 or more days per week of vigorous intensity exercise for 20+ minutes per day for an accumulated total of 75 minutes or more of exercise per week
- vigorous intensity exercises are estimated at 70-85% of your Max Heart Rate

### Nutrition
- 45-65% of daily calories from carbohydrates, 25-35% of daily calories from fat, with <10% from saturated fat and 10%–35% of calories from protein.
- Carbohydrates are classified as sugar, starch and fiber. **Sugar** is a type of simple carbohydrate, which is digested rapidly and causes a surge of energy, followed by a crash once metabolized.  **Starches** are complex carbohydrates which take the body longer to break down and therefore provide a more sustained amount of energy and don’t cause a crash. Common examples are whole-grain bread, legumes and food high in fiber. Fiber is a crucial type of carbohydrate as it can’t be digested fully and therefore helps to maintain intestinal health.
- In general, it is best to limit consumption of simple carbohydrates and opt for complex carbohydrates and fiber when possible.
- Healthy fats are typically unsaturated and include nuts, seeds, some types of fish, walnuts and peanut butter. Fats with less health benefits often have large amounts of saturated fats and include butter, ice cream, and some red meat
- 45g grams of protein perday
- adequate intake of 2,700 ml/day for young women (ages 19-30) and 3,700 ml/day for young men (ages 19-30) which is about 11-15 cups per day.
- vitamin:  [vitamins and minerals](https://www.hsph.harvard.edu/nutritionsource/vitamins/)

# Computer
## Graphics
- [great interactive visual guide to everything](https://ciechanow.ski/lights-and-shadows/)(https://ciechanow.ski/cameras-and-lenses/)(https://ciechanow.ski/curves-and-surfaces/)

### 3D ML Models
- [NeRF]
- [Gaussian Splatting](https://repo-sam.inria.fr/fungraph/3d-gaussian-splatting/3d_gaussian_splatting_low.pdf)
- [text to 4d with Gaussian](https://research.nvidia.com/labs/toronto-ai/AlignYourGaussians/): 1. multiview text-guided latent diffusion model MVDream and the general text-to-image latent diffusion model Stable Diffusion during score distillation 2. optimize the 3D Gaussians 3. combine the text-to-video and the text-to-image models and optimize the deformation field to generate the temporal dynamics

# AI
## General Notes
### Book Notes
CS229:
- h is the hypothesis, or our approximate function
- θ is parameter 
- J is cost function. eg MSE: ${J(\theta)=1/2\sum_{i}{(\theta^Tx_i-y_i)^2}}$
- linear model: $h(x)=\theta^Tx$
- LMS update: ${\theta_j:=\theta_j+\alpha(y^i-h_{\theta}(x^i))x_j^i}$
- superscript is sample number usually i from 0 to d; subscript is data dimension also i from 0 to n
## Traditional
### SVM
See CS229 notes

## NN
### Representation
- [linear representation hypothesis](https://arxiv.org/abs/2311.03658): high-level concepts are represented linearly as directions in some representation space
- [UNIVERSAL NEURONS IN GPT2](https://arxiv.org/abs/2401.12181): 
    - 1-5% of neurons are universal. they usually have clear interpretations. deactivating attention heads, changing the entropy of the next token distribution, and predicting the next token to(not) be within a particular set. 
    - Olah et al. (2020b) propose three speculative claims regarding the interpretation of artificial neural networks: that features—directions in activation space representing properites of the input—are the fundamental unit of analysis, that features are connected into circuits via network weights, and that features and circuits are universal across model
    - semantic features neurons corresponding to coherent topics (Lim and Lauw, 2023), concepts (Elhage et al., 2022a), or contexts (Gurnee et al., 2023).

# Engineering
## AR
### Control
- [contact lens RF detection](https://www.nature.com/articles/s41467-024-47851-y)
- [SSVEP](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640776/): 60 characters/min
- [color muse 2](https://arxiv.org/pdf/2008.07092)
- voice:
- head/hand/foot movement
- gaze
- Facial Gestures
- Pose Detection
- EMG sensors 


## Brain Hacks
### EEG Interpretation
- [typing mega thread](https://openbci.com/forum/index.php?p=/discussion/206/openvibe-p300-speller-tutorial-questions)
- [indian boy thread](https://anushmutyala.medium.com/muse-101-how-to-start-developing-with-the-muse-2-right-now-a1b87119be5c)

# Music
## Tools
- [online frequency analyzer](https://www.maztr.com/audiospectrumanalyzer)


-------------------------------



# Life Tools
##
### Math Animation 
https://github.com/ManimCommunity/manim/






# By Source
## Books
### The man who solved the market (Simons biography)
